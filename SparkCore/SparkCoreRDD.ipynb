{"cells":[{"cell_type":"code","source":["# using python list collections to load data.\nmy_list = [1,2,3,4,5,6,7,8,9,10]"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#checking type of list\ntype(my_list)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#Applying function to input data \nsquared_list = map(lambda x:x**2,my_list)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#checking type where it is changed to map from list.\ntype(squared_list)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["#print the data\nprint (squared_list)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["#print the content.\nfor i in squared_list:\n  print (i)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# using python list collections to load data.\nmy_list_spark = [1,2,3,4,5,6,7,8,9,10]"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["#check type of collection \ntype(my_list_spark)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# Convert it into Spark RDD \nlist_spark = sc.parallelize(my_list_spark)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["#check type of variable\ntype(list_spark)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#apply the function \nspark_first_rdd = list_spark.map(lambda x: x+1)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["#apply action on it.\nspark_first_rdd.take(10)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["#Read a textfile in spark [Unstructured data]\ntextFile = sc.textFile(\"/my/directory/*.txt\")"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["#Read a directory of textfiles in spark. [Unstructured data] \ntextFile2 = sc.wholeTextFiles(\"/my/directory/\")"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["rdd = sc.parallelize([('a',7),('a',2),('b',2)])\nrdd2 = sc.parallelize([('a',2),('d',1),('b',1)])\nrdd3 = sc.parallelize(range(1000))"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["#List the number of partitions\nrdd.getNumPartitions()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["# Count RDD instances\nrdd.count()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["#Count RDD instances by key\nrdd.countByKey()"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["# Count RDD instances by value\nrdd.countByValue()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["#Return (key,value) pairs as a dictionary\nrdd.collectAsMap()\n {'a': 2,'b': 2}"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["#Sum of RDD elements\nrdd3.sum()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["#Check whether RDD is empty\nsc.parallelize([]).isEmpty()\nrdd.isEmpty()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["#Maximum value of RDD elements\nrdd3.max()"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["#Minimum value of RDD elements\nrdd3.min()"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# Mean value of RDD elements\nrdd3.mean()"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["#Standard deviation of RDD elements\nrdd3.stdev()"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["# Compute variance of RDD elements\nrdd3.histogram(3)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["# Summary statistics (count, mean, stdev, max & min)\nrdd3.stats()"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["# Apply a function to each RDD element \nrdd.map(lambda x: x+(x[1],x[0])).collect()"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["# Apply a function to each RDD element and flatten the result\nrdd5 = rdd.flatMap(lambda x: x+(x[1],x[0]))\n"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["# Return a list with all RDD elements\nrdd.collect()\n# Take first 2 RDD elements\nrdd.take(10)\n# Take first RDD element\nrdd.first()\n# Take top 2 RDD elements\nrdd.top(2)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["# Return sampled subset of rdd3\nrdd3.sample(False, 0.15, 81).collect()"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["#Filter the RDD\nrdd.filter(lambda x: \"a\" in x).collect()\n\n# Return distinct RDD values\nrdd5.distinct().collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[52]: [(&#39;a&#39;, 7), (&#39;a&#39;, 2)]</div>"]}}],"execution_count":33},{"cell_type":"code","source":["def g(x): print(x)\nrdd.foreach(g)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":34},{"cell_type":"code","source":["# Reducing \n# Merge the rdd values for each key\nrdd.reduceByKey(lambda x,y : x+y).collect()\n\n# Merge the rdd values\nrdd.reduce(lambda a, b: a + b)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["#Return RDD of grouped values \nrdd3.groupBy(lambda x: x % 2)\n        .mapValues(list)\n        .collect()\n    \n# Group rdd by key\nrdd.groupByKey()\n.mapValues(list)\n     .collect()    \n    "],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["# Aggregate RDD elements of each partition and then the results\nseqOp = (lambda x,y: (x[0]+y,x[1]+1)) \ncombOp = (lambda x,y:(x[0]+y[0],x[1]+y[1]))\nrdd3.aggregate((0,0),seqOp,combOp) \n\n#Aggregate values of each RDD key\nrdd.aggregateByKey((0,0),seqop,combop)\n       .collect()\n\n# Aggregate the elements of each partition, and then the results\nrdd3.fold(0,add)\n\n# Merge the values for each key\nrdd.foldByKey(0, add)\n       .collect() \n  \n# Create tuples of RDD elements by applying a function  \nrdd3.keyBy(lambda x: x+x)\n.collect()  "],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["#Return each rdd value not contained in rdd2\nrdd.subtract(rdd2)\n      .collect()\n  \n# Return each (key,value) pair of rdd2 with no matching key in rdd\nrdd2.subtractByKey(rdd)\n      .collect()\n  \n# Return the Cartesian product of rdd and rdd2\nrdd.cartesian(rdd2).collect()   \n  "],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["#Sort RDD by given function.\nrdd2.sortBy(lambda x: x[1])\n        .collect()\n\n #rdd2.sortByKey()\n  rdd2.sortByKey()\n      .collect()"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["#New RDD with 4 partitions\nrdd.repartition(4)\n\n#Decrease the number of partitions in the RDD to 1\nrdd.coalesce(1)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[54]: CoalescedRDD[78] at coalesce at NativeMethodAccessorImpl.java:0</div>"]}}],"execution_count":40},{"cell_type":"code","source":["rdd.saveAsTextFile(\"rdd.txt\")\nrdd.saveAsHadoopFile(\"hdfs://namenodehost/parent/child\",'org.apache.hadoop.mapred.TextOutputFormat')"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["sc.stop()"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":43}],"metadata":{"name":"SparkCoreRDD","notebookId":3913013655120226},"nbformat":4,"nbformat_minor":0}
